{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ¥ Notebook 3: Machine Learning with Tabular Data\n",
        "\n",
        "In this notebook, weâ€™ll shift from images to **tabular clinical data**.  \n",
        "Youâ€™ll predict whether a patient is likely to have diabetes using routine measurements from the **Pima Indians Diabetes** dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Learning Objectives\n",
        "By the end, you will be able to:\n",
        "1. Load and explore a real clinical tabular dataset.\n",
        "2. Clean data (handle missing/invalid values) and engineer features.\n",
        "3. Build a robust ML pipeline (imputation â†’ scaling â†’ model).\n",
        "4. Train, tune, and evaluate a classifier with appropriate metrics.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Clinical Context\n",
        "In many clinical settings, **tabular data**â€”vitals, lab values, demographicsâ€”is the primary source of information.  \n",
        "A well-built model can support **risk screening** and trigger further clinical assessment.\n",
        "\n",
        "> âš ï¸ This is an *educational* exercise. Do **not** use these models for real clinical decisions.\n"
      ],
      "metadata": {
        "id": "N9c9FEiSqCSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install/Import (Colab) { display-mode: \"form\" }\n",
        "# Minimal installs; most are preinstalled on Colab\n",
        "!pip -q install scikit-learn pandas numpy matplotlib seaborn\n",
        "\n",
        "import io, os, sys, math, json, time, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support, classification_report,\n",
        "    confusion_matrix, roc_auc_score, RocCurveDisplay\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "print(\"âœ… Environment ready\")\n"
      ],
      "metadata": {
        "id": "DXiVWzlqhMsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Data Exploration, Cleaning, and Preprocessing\n",
        "\n",
        "Weâ€™ll use the Pima Indians Diabetes dataset (binary label: `outcome`).  \n",
        "Certain physiological measures in the raw file sometimes contain **invalid zeros** (e.g., `glucose == 0`), which weâ€™ll treat as missing and impute.\n",
        "\n",
        "**Steps**\n",
        "1. Load dataset from URL or upload your own CSV.\n",
        "2. Inspect schema and summary stats.\n",
        "3. Mark impossible zeros as missing and **impute**.\n",
        "4. (Optional) Feature scaling for linear/SVM models.\n"
      ],
      "metadata": {
        "id": "bIJMI18DhQkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Dataset (URL or Upload) { run: \"auto\" }\n",
        "use_url = True  #@param {type:\"boolean\"}\n",
        "data_url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\" #@param {type:\"string\"}\n",
        "# Column names from the dataset description\n",
        "column_names = [\n",
        "    \"pregnancies\",\"glucose\",\"blood_pressure\",\"skin_thickness\",\n",
        "    \"insulin\",\"bmi\",\"diabetes_pedigree\",\"age\",\"outcome\"\n",
        "]\n",
        "\n",
        "if use_url:\n",
        "    df = pd.read_csv(data_url, names=column_names)\n",
        "else:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    fname = list(uploaded.keys())[0]\n",
        "    df = pd.read_csv(io.BytesIO(uploaded[fname]), names=column_names)\n",
        "\n",
        "print(\"âœ… Loaded data with shape:\", df.shape)\n",
        "display(df.head())\n"
      ],
      "metadata": {
        "id": "7N2qslqvhNU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Quick Audit (Info & Stats)\n",
        "print(\"Data Types / Non-null counts\")\n",
        "print(df.info())\n",
        "print(\"\\nSummary statistics\")\n",
        "display(df.describe(include='all'))\n",
        "print(\"\\nClass balance (outcome):\")\n",
        "print(df['outcome'].value_counts(normalize=True).rename('proportion'))\n"
      ],
      "metadata": {
        "id": "FNdVECedhPZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mark Impossible Zeros as Missing & Impute { run: \"auto\" }\n",
        "# Columns where zero is physiologically implausible in this dataset representation\n",
        "zero_as_missing = [\"glucose\",\"blood_pressure\",\"skin_thickness\",\"insulin\",\"bmi\"]\n",
        "\n",
        "df_clean = df.copy()\n",
        "for c in zero_as_missing:\n",
        "    zeros = (df_clean[c] == 0).sum()\n",
        "    if zeros > 0:\n",
        "        print(f\"âš ï¸ Found {zeros} zero(s) in {c}; setting to NaN\")\n",
        "        df_clean.loc[df_clean[c] == 0, c] = np.nan\n",
        "\n",
        "print(\"\\nMissing values per column (after marking zeros):\")\n",
        "print(df_clean.isna().sum())\n",
        "\n",
        "# We'll impute later inside a pipeline; preview a simple mean-impute copy for EDA:\n",
        "df_preview = df_clean.copy()\n",
        "for c in zero_as_missing:\n",
        "    df_preview[c] = df_preview[c].fillna(df_preview[c].mean())\n",
        "\n",
        "display(df_preview.head())\n"
      ],
      "metadata": {
        "id": "2Qjy-0jdhUk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visual EDA (Hist, Correlation) { run: \"auto\" }\n",
        "fig, axes = plt.subplots(3, 3, figsize=(12, 10))\n",
        "axes = axes.ravel()\n",
        "for i, col in enumerate(df.columns[:-1]):  # exclude outcome\n",
        "    axes[i].hist(df_preview[col].dropna(), bins=30)\n",
        "    axes[i].set_title(col)\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df_preview.corr(numeric_only=True), annot=False)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ud72O4Z1hYSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Model Selection, Training, and Tuning\n",
        "\n",
        "Weâ€™ll assemble a **Pipeline** to ensure leakage-free preprocessing and reproducibility:\n",
        "\n",
        "- **Imputer**: replace missing with median\n",
        "- **Scaler**: (optional) standardize features\n",
        "- **Estimator**: choose among Logistic Regression / Random Forest / SVM\n",
        "\n",
        "Use the form to pick model and hyperparameters.\n"
      ],
      "metadata": {
        "id": "5e5y7E4Hhaig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Split + Pipeline + Model Choice (Form) { display-mode: \"form\" }\n",
        "test_size = 0.2            #@param {type:\"number\"}\n",
        "random_state = 42          #@param {type:\"number\"}\n",
        "scale_features = True      #@param {type:\"boolean\"}\n",
        "\n",
        "model_choice = \"RandomForest\"  #@param [\"RandomForest\",\"LogisticRegression\",\"SVM\"]\n",
        "\n",
        "# RandomForest params\n",
        "rf_n_estimators = 300      #@param {type:\"integer\"}\n",
        "rf_max_depth = 6           #@param {type:\"integer\"}\n",
        "rf_min_samples_leaf = 2    #@param {type:\"integer\"}\n",
        "\n",
        "# LogisticRegression params\n",
        "lr_C = 1.0                 #@param {type:\"number\"}\n",
        "lr_penalty = \"l2\"          #@param [\"l2\",\"l1\"]\n",
        "lr_solver = \"liblinear\"    #@param [\"liblinear\",\"lbfgs\",\"saga\"]\n",
        "\n",
        "# SVM params\n",
        "svm_C = 1.0                #@param {type:\"number\"}\n",
        "svm_kernel = \"rbf\"         #@param [\"linear\",\"rbf\",\"poly\"]\n",
        "\n",
        "# Features/Target\n",
        "X = df_clean.drop(columns=[\"outcome\"])\n",
        "y = df_clean[\"outcome\"].astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=float(test_size), stratify=y, random_state=int(random_state)\n",
        ")\n",
        "\n",
        "# Numeric columns\n",
        "num_features = X.columns.tolist()\n",
        "\n",
        "num_transformers = []\n",
        "num_transformers.append((\"imputer\", SimpleImputer(strategy=\"median\")))\n",
        "if scale_features:\n",
        "    num_transformers.append((\"scaler\", StandardScaler()))\n",
        "\n",
        "preprocess = Pipeline(num_transformers)\n",
        "\n",
        "if model_choice == \"RandomForest\":\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=int(rf_n_estimators),\n",
        "        max_depth=int(rf_max_depth),\n",
        "        min_samples_leaf=int(rf_min_samples_leaf),\n",
        "        random_state=int(random_state),\n",
        "        class_weight=\"balanced\"  # helps with class imbalance\n",
        "    )\n",
        "elif model_choice == \"LogisticRegression\":\n",
        "    clf = LogisticRegression(\n",
        "        C=float(lr_C),\n",
        "        penalty=lr_penalty,\n",
        "        solver=lr_solver,\n",
        "        random_state=int(random_state),\n",
        "        max_iter=300,\n",
        "        class_weight=\"balanced\"\n",
        "    )\n",
        "else:\n",
        "    clf = SVC(\n",
        "        C=float(svm_C),\n",
        "        kernel=svm_kernel,\n",
        "        probability=True,\n",
        "        random_state=int(random_state),\n",
        "        class_weight=\"balanced\"\n",
        "    )\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"model\", clf)\n",
        "])\n",
        "\n",
        "print(\"âœ… Pipeline ready:\", pipe)\n"
      ],
      "metadata": {
        "id": "3jKijdqXhZm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Model\n",
        "pipe.fit(X_train, y_train)\n",
        "print(\"âœ… Model training complete!\")"
      ],
      "metadata": {
        "id": "dijeNzyihih6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Model Testing & Inference\n",
        "\n",
        "Weâ€™ll compute:\n",
        "- Accuracy, Precision, Recall, F1\n",
        "- Confusion Matrix\n",
        "- ROC-AUC & ROC curve\n",
        "\n",
        "> In screening contexts, **Recall (Sensitivity)** is especially important.\n"
      ],
      "metadata": {
        "id": "a-o-GbJvhos7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate Model\n",
        "y_pred = pipe.predict(X_test)\n",
        "y_proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe.named_steps[\"model\"], \"predict_proba\") else None\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\")\n",
        "\n",
        "print(f\"Accuracy:  {acc:.3f}\")\n",
        "print(f\"Precision: {prec:.3f}\")\n",
        "print(f\"Recall:    {rec:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")\n",
        "\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "if y_proba is not None:\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    print(f\"ROC-AUC: {auc:.3f}\")\n",
        "    RocCurveDisplay.from_predictions(y_test, y_proba)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Model does not expose predict_proba; ROC-AUC not computed.\")\n"
      ],
      "metadata": {
        "id": "7q5_tsbWho_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§ª Exercise: Try a Different Model\n",
        "\n",
        "- Switch `model_choice` (e.g., Logistic Regression or SVM).\n",
        "- Toggle `scale_features`.\n",
        "- Adjust hyperparameters.\n",
        "- Observe: Which model **improves Recall** without destroying Precision?\n",
        "\n",
        "> ðŸ’¡ Bonus: Add polynomial features or try `class_weight=None` and compare.\n"
      ],
      "metadata": {
        "id": "DpTKXarchqX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Feature Importance for Trees\n",
        "is_rf = isinstance(pipe.named_steps[\"model\"], RandomForestClassifier)\n",
        "if is_rf:\n",
        "    importances = pipe.named_steps[\"model\"].feature_importances_\n",
        "    idx = np.argsort(importances)[::-1]\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.barplot(x=importances[idx], y=np.array(X.columns)[idx])\n",
        "    plt.title(\"Random Forest Feature Importance\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Feature importance plot only shown for RandomForest.\")"
      ],
      "metadata": {
        "id": "6xi7wOcihrtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Sum Up and Reflection\n",
        "\n",
        "### What you accomplished\n",
        "- Cleaned and imputed clinical tabular data.\n",
        "- Built a robust sklearn pipeline.\n",
        "- Trained, tuned, and evaluated multiple classifiers.\n",
        "\n",
        "### Reflection prompts\n",
        "1. In screening tasks, is **Recall** or **Precision** more important? Why?\n",
        "2. What are potential sources of **bias** in this dataset?\n",
        "3. How would you update the pipeline for **temporal validation** (simulating deployment in the future)?\n",
        "\n",
        "---\n",
        "\n",
        "### Next steps\n",
        "- Notebook 4: **AI Engineering** â€” deploy as an API and monitor in production."
      ],
      "metadata": {
        "id": "oRYGTeSZhuvz"
      }
    }
  ]
}
