{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üè• Notebook 2: Computer Vision in Healthcare\n",
        "\n",
        "In this notebook, you‚Äôll apply what you learned to a real healthcare problem:  \n",
        "**detecting pneumonia from chest X-ray images**.  \n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "By the end of this notebook, you will be able to:\n",
        "1. Prepare medical images (X-rays) for training a deep learning model.  \n",
        "2. Apply **transfer learning** using ResNet to a healthcare task.  \n",
        "3. Evaluate model performance and interpret results.  \n",
        "4. Reflect on the limitations and ethical considerations of AI in medicine.  \n",
        "\n",
        "---\n",
        "\n",
        "## üè• Why this matters\n",
        "- Pneumonia is a leading cause of death worldwide.  \n",
        "- Radiologists often need to examine thousands of X-rays under time pressure.  \n",
        "- AI models can help **assist diagnosis** by flagging suspicious cases.  \n",
        "\n",
        "üëâ In this notebook, you‚Äôll **train a CNN to detect pneumonia** using chest X-rays.\n"
      ],
      "metadata": {
        "id": "N9c9FEiSqCSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.0 Load Public Dataset from Kaggle ‚Äî Chest X-Ray (Pneumonia)\n",
        "\n",
        "We‚Äôll use the well-known **Chest X-Ray Images (Pneumonia)** dataset from Kaggle.\n",
        "\n",
        "**What this cell block does:**\n",
        "1) Authenticates to Kaggle (upload `kaggle.json` once)  \n",
        "2) Downloads & extracts the dataset  \n",
        "3) Builds **PyTorch DataLoaders** for train/val/test  \n"
      ],
      "metadata": {
        "id": "ta5gbMSJot5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Kaggle CLI + Prepare Auth (one-time per runtime)\n",
        "!pip -q install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "import os, json, pathlib, shutil\n",
        "\n",
        "use_manual_upload = True  #@param {type:\"boolean\"}\n",
        "# If you prefer to paste creds manually, set use_manual_upload=False and fill below\n",
        "kaggle_username = \"\"  # @param {type:\"string\"}\n",
        "kaggle_key = \"\"       # @param {type:\"string\"}\n",
        "\n",
        "kaggle_dir = pathlib.Path.home() / \".kaggle\"\n",
        "kaggle_dir.mkdir(exist_ok=True)\n",
        "\n",
        "if use_manual_upload:\n",
        "    print(\"üì• Please upload your kaggle.json (Account > Create New API Token)\")\n",
        "    uploaded = files.upload()\n",
        "    if \"kaggle.json\" not in uploaded:\n",
        "        raise ValueError(\"kaggle.json not uploaded. Try again.\")\n",
        "    with open(kaggle_dir / \"kaggle.json\", \"wb\") as f:\n",
        "        f.write(uploaded[\"kaggle.json\"])\n",
        "else:\n",
        "    if not kaggle_username or not kaggle_key:\n",
        "        raise ValueError(\"Fill in kaggle_username and kaggle_key or toggle manual upload.\")\n",
        "    creds = {\"username\": kaggle_username, \"key\": kaggle_key}\n",
        "    with open(kaggle_dir / \"kaggle.json\", \"w\") as f:\n",
        "        json.dump(creds, f)\n",
        "\n",
        "os.chmod(kaggle_dir / \"kaggle.json\", 0o600)\n",
        "print(\"‚úÖ Kaggle credentials set.\")\n"
      ],
      "metadata": {
        "id": "0WUuL9h4orZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download & Unzip the Chest X-Ray (Pneumonia) Dataset\n",
        "# Dataset: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
        "DATA_ROOT = \"/content/data\"  #@param {type:\"string\"}\n",
        "\n",
        "os.makedirs(DATA_ROOT, exist_ok=True)\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p \"$DATA_ROOT\" -q\n",
        "\n",
        "zip_path = os.path.join(DATA_ROOT, \"chest-xray-pneumonia.zip\")\n",
        "!unzip -q -o \"$zip_path\" -d \"$DATA_ROOT\"\n",
        "\n",
        "# After unzip, structure is: /content/data/chest_xray/{train,val,test}/{NORMAL,PNEUMONIA}\n",
        "base_dir = os.path.join(DATA_ROOT, \"chest_xray\")\n",
        "assert os.path.isdir(base_dir), \"Dataset folder chest_xray not found after unzip.\"\n",
        "print(\"‚úÖ Dataset ready at:\", base_dir)\n",
        "!find \"$base_dir\" -maxdepth 2 -type d -print\n"
      ],
      "metadata": {
        "id": "5ckhdF7KoxFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Data Preparation\n",
        "\n",
        "Medical images are often:\n",
        "- Different sizes (512√ó512, 1024√ó1024, etc.)  \n",
        "- Different intensity ranges (depending on the scanner used)  \n",
        "\n",
        "We‚Äôll:\n",
        "1. Resize all images to **224√ó224**  \n",
        "2. Convert them to tensors (numerical format)  \n",
        "3. Normalize pixel values  \n"
      ],
      "metadata": {
        "id": "b9HgBeJvqJt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Transforms & Build DataLoaders\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "# Augmentations for train; light transforms for val/test\n",
        "img_size = 224  #@param {type:\"integer\"}\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=8),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "eval_tfms = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir   = os.path.join(base_dir, \"val\")\n",
        "test_dir  = os.path.join(base_dir, \"test\")\n",
        "\n",
        "train_ds = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
        "val_ds   = datasets.ImageFolder(val_dir,   transform=eval_tfms)\n",
        "test_ds  = datasets.ImageFolder(test_dir,  transform=eval_tfms)\n",
        "\n",
        "batch_size = 32  #@param {type:\"integer\"}\n",
        "num_workers = 2  #@param {type:\"integer\"}\n",
        "\n",
        "# Handle class imbalance with weighted sampler (optional)\n",
        "targets = np.array([y for _, y in train_ds.samples])\n",
        "class_counts = np.bincount(targets)\n",
        "class_weights = 1.0 / class_counts\n",
        "sample_weights = class_weights[targets]\n",
        "sampler = WeightedRandomSampler(weights=torch.DoubleTensor(sample_weights),\n",
        "                                num_samples=len(sample_weights),\n",
        "                                replacement=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=num_workers, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(\"‚úÖ DataLoaders ready.\")\n",
        "print(\"Classes:\", train_ds.classes)\n",
        "print(\"Train/Val/Test sizes:\", len(train_ds), len(val_ds), len(test_ds))\n"
      ],
      "metadata": {
        "id": "hPoZmZ4lZ2B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Peek at a Few Training Images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_batch(dl, n=8):\n",
        "    xb, yb = next(iter(dl))\n",
        "    n = min(n, xb.size(0))\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        # unnormalize for display\n",
        "        img = xb[i].clone()\n",
        "        img = img * 0.5 + 0.5\n",
        "        plt.imshow(img[0].cpu(), cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(train_ds.classes[yb[i].item()])\n",
        "    plt.show()\n",
        "\n",
        "show_batch(train_loader, n=8)\n"
      ],
      "metadata": {
        "id": "chW1O8kGqFs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Transfer Learning with ResNet\n",
        "\n",
        "Instead of building a CNN from scratch, we‚Äôll use **ResNet18**,  \n",
        "pre-trained on ImageNet, and fine-tune it for pneumonia detection.\n",
        "\n",
        "Why transfer learning?\n",
        "- Saves compute time  \n",
        "- Works well with smaller medical datasets  \n",
        "- Learns general features (edges, textures) and adapts them to X-rays\n"
      ],
      "metadata": {
        "id": "UiLBLhySf0CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Pretrained ResNet Model\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify final layer for binary classification (pneumonia vs normal)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 2)\n",
        "\n",
        "print(\"‚úÖ ResNet18 ready for pneumonia classification!\")\n"
      ],
      "metadata": {
        "id": "BEXNgKSzZ4ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Model Training\n",
        "\n",
        "We‚Äôll fine-tune the model on our dataset.  \n",
        "This may take a while depending on your dataset size.  \n",
        "\n",
        "üëâ For teaching purposes, we‚Äôll show the training loop structure here.\n"
      ],
      "metadata": {
        "id": "P66W_FjGf56o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Training Loop (simplified)\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=2):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} complete ‚úÖ\")\n"
      ],
      "metadata": {
        "id": "nQgjsaLff5uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train/Eval with Your Existing Model & Loops\n",
        "# Assumes you've already defined:\n",
        "#   - `model` (e.g., ResNet18 with model.fc = nn.Linear(..., 2))\n",
        "#   - `train_model(model, train_loader, val_loader, epochs=...)`\n",
        "#   - `evaluate_model(model, test_loader)` returning (acc, cm)\n",
        "\n",
        "epochs = 2  #@param {type:\"integer\"}\n",
        "\n",
        "print(\"üèãÔ∏è Training...\")\n",
        "train_model(model, train_loader, val_loader, epochs=epochs)\n"
      ],
      "metadata": {
        "id": "8K5fC9nQpYSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Model Testing & Evaluation\n",
        "\n",
        "Now let‚Äôs test the model on unseen data and check its performance.  \n",
        "\n",
        "We‚Äôll calculate:\n",
        "- Accuracy  \n",
        "- Confusion matrix  \n",
        "- Example predictions  \n",
        "\n",
        "üëâ In healthcare, evaluation is **critical** ‚Äî a wrong prediction can mean a missed diagnosis.\n"
      ],
      "metadata": {
        "id": "ygbioWUHf8_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate the Model\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            all_preds.extend(preds.numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    return acc, cm\n"
      ],
      "metadata": {
        "id": "Ss9JGNRZf9iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üß™ Testing...\")\n",
        "acc, cm = evaluate_model(model, test_loader)\n",
        "print(f\"Test Accuracy: {acc:.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "iBUvduugpbmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Capstone Project\n",
        "\n",
        "Now it‚Äôs your turn üöÄ  \n",
        "\n",
        "- Train your model on the pneumonia dataset  \n",
        "- Evaluate its performance  \n",
        "- Visualize some misclassified cases  \n",
        "\n",
        "üí° **Challenge:**  \n",
        "What patterns do you notice in the X-rays that were misclassified?  \n",
        "Could they confuse even a human radiologist?\n"
      ],
      "metadata": {
        "id": "oqv2x7ltf__h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåç Ethics & Limitations\n",
        "\n",
        "AI in healthcare is powerful but not perfect.  \n",
        "Consider these questions:\n",
        "- What are the risks of false negatives in pneumonia detection?  \n",
        "- How might bias in the dataset (e.g., only one hospital‚Äôs patients) affect results?  \n",
        "- Should AI replace radiologists, or assist them?  \n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ Congratulations! You‚Äôve built your first medical AI pipeline.  \n",
        "In the next notebook, we‚Äôll explore **federated learning** to train across hospitals without sharing patient data.\n"
      ],
      "metadata": {
        "id": "QAKszN9xgBkp"
      }
    }
  ]
}